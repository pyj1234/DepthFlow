from collections.abc import Iterable
from pathlib import Path
from typing import Annotated, Optional, Union

import json, shutil
import numpy as np
import validators
from attrs import Factory, define
from imgui_bundle import imgui
from PIL import Image
from PIL.Image import Image as ImageType
from pydantic import Field, HttpUrl
from shaderflow.exceptions import ShaderBatchStop
from shaderflow.message import ShaderMessage
from shaderflow.scene import ShaderScene
from shaderflow.texture import ShaderTexture
from shaderflow.variable import ShaderVariable
from typer import Option

from broken.envy import Environment
from broken.externals.depthmap import (
    DepthAnythingV2,
    DepthEstimator,
    DepthPro,
    Marigold,
    ZoeDepth,
)
from broken.externals.upscaler import (
    BrokenUpscaler,
    NoUpscaler,
    Realesr,
    Upscayl,
    Waifu2x,
)
from broken.loaders import LoadableImage, LoadImage
from broken.path import BrokenPath
from broken.types import FileExtensions
from broken.utils import flatten, list_get
from depthflow import DEPTHFLOW, DEPTHFLOW_ABOUT
from depthflow.animation import (
    Animation,
    ComponentBase,
    DepthAnimation,
    FilterBase,
    PresetBase,
)
from depthflow.state import DepthState

# [æ–°å¢] å¯¼å…¥ç”Ÿæˆå™¨æ¨¡å—
try:
    from depthflow.generator import generate_background_ai

    HAS_GENAI = True
except ImportError:
    HAS_GENAI = False
    print("Warning: Generator dependencies not installed (diffusers, transformers).")

PydanticImage = Union[str, HttpUrl, Path]

# -------------------------------------------------------------------------------------------------|

DEFAULT_IMAGE: str = "https://w.wallhaven.cc/full/pk/wallhaven-pkz5r9.png"
DEPTH_SHADER: Path = (DEPTHFLOW.RESOURCES.SHADERS / "depthflow.glsl")


# === 1. ã€æ–°å¢ã€‘æ·±åº¦å›¾å½’ä¸€åŒ–è¾…åŠ©å‡½æ•° ===
def normalize_and_convert_depth(depth_pil: ImageType) -> ImageType:
    """å°†æµ®ç‚¹æ·±åº¦å›¾ (Mode 'F') å½’ä¸€åŒ–å¹¶è½¬æ¢ä¸º 8ä½ç°åº¦å›¾ (Mode 'L')"""
    # ç¡®ä¿æ˜¯ ImageType
    if isinstance(depth_pil, np.ndarray):
        depth_pil = Image.fromarray(depth_pil)

    if depth_pil.mode == 'F':
        # å°† PIL Image è½¬æ¢ä¸º numpy æ•°ç»„
        depth_np = np.array(depth_pil, dtype=np.float32)

        # å½’ä¸€åŒ–åˆ° 0-1 èŒƒå›´
        d_min = depth_np.min()
        d_max = depth_np.max()
        if d_max > d_min:
            depth_np = (depth_np - d_min) / (d_max - d_min)
        else:
            # é˜²æ­¢é™¤ä»¥é›¶
            depth_np = np.full_like(depth_np, 0.5)

            # æ‰©å±•åˆ° 0-255ï¼Œå¹¶è½¬ä¸º uint8
        depth_np = (depth_np * 255.0).astype('uint8')

        # è½¬æ¢å› PIL Image (Mode 'L')
        return Image.fromarray(depth_np, mode='L')

    # å·²ç»æ˜¯ 8ä½ç°åº¦å›¾ï¼Œç¡®ä¿æ¨¡å¼ä¸º 'L'
    if depth_pil.mode == 'L' or depth_pil.mode == 'P':
        return depth_pil.convert('L')

    return depth_pil.convert('L')  # å¼ºåˆ¶è½¬æ¢ï¼Œä»¥é˜²ä¸‡ä¸€


@define
class DepthScene(ShaderScene):
    state: DepthState = Factory(DepthState)

    # [æ–°å¢] ç”¨äºå¯¼å‡ºçš„ PIL Image ç¼“å­˜å±æ€§
    pil_image_cache: Optional[ImageType] = None
    pil_depth_cache: Optional[ImageType] = None
    pil_bg_cache: Optional[ImageType] = None
    pil_bg_depth_cache: Optional[ImageType] = None
    pil_mask_cache: Optional[ImageType] = None

    def export_mobile(self, output_dir: str = "mobile_assets") -> None:
        """å¯¼å‡ºç”¨äºç§»åŠ¨ç«¯æ¸²æŸ“çš„æ‰€æœ‰èµ„äº§"""
        out_path = Path(output_dir)
        out_path.mkdir(parents=True, exist_ok=True)
        self.log_info(f"ğŸ“¦ æ­£åœ¨å¯¼å‡ºèµ„äº§åˆ°: {out_path.absolute()}")

        # å®šä¹‰ä¸€ä¸ªç®€å•çš„ä¿å­˜å‡½æ•°ï¼Œç›´æ¥ä½¿ç”¨ç¼“å­˜çš„ PIL å¯¹è±¡
        def save_pil(pil_obj: Optional[ImageType], name: str):
            if pil_obj is not None:
                # ç¡®ä¿ Mask æ˜¯ L æ¨¡å¼ï¼Œå…¶ä»–æ˜¯ RGB (æ·±åº¦å›¾åœ¨ç¼“å­˜æ—¶å·²è½¬ä¸º L)
                if name == "subject_mask" or name == "depth" or name == "depth_bg":
                    if pil_obj.mode != "L": pil_obj = pil_obj.convert("L")
                else:
                    if pil_obj.mode != "RGB": pil_obj = pil_obj.convert("RGB")

                # PNG å¯¼å‡º
                pil_obj.save(out_path / f"{name}.png")
            else:
                self.log_error(f"âŒ å¯¼å‡ºå¤±è´¥: {name} ç¼“å­˜ä¸ºç©º")

        # ä½¿ç”¨ç¼“å­˜çš„ PIL å¯¹è±¡
        if self.pil_image_cache:
            save_pil(self.pil_image_cache, "image")
            save_pil(self.pil_depth_cache, "depth")
            save_pil(self.pil_bg_cache, "image_bg")
            save_pil(self.pil_bg_depth_cache, "depth_bg")
            save_pil(self.pil_mask_cache, "subject_mask")
        else:
            self.log_error("âŒ æ— æ³•å¯¼å‡ºï¼šPIL å›¾åƒç¼“å­˜ä¸ºç©ºã€‚è¯·ç¡®ä¿ _load_inputs å·²æˆåŠŸæ‰§è¡Œã€‚")
            return

        # 2. å¯¼å‡ºå‚æ•° (Config.json)
        config = {
            "height": self.state.height,
            "steady": self.state.steady,
            "focus": self.state.focus,
            "zoom": self.state.zoom,
            "isometric": self.state.isometric,
            "offset_x": self.state.offset_x,
            "offset_y": self.state.offset_y,
            "animation_type": "orbital",  # ç¤ºä¾‹
            "resolution": self.resolution
        }

        with open(out_path / "config.json", "w") as f:
            json.dump(config, f, indent=4)

        self.log_info("âœ… å¯¼å‡ºå®Œæˆï¼è¯·å°† 'mobile_assets' æ–‡ä»¶å¤¹å†…å®¹å¤åˆ¶åˆ° Android çš„ assets ç›®å½•ã€‚")

    class Config(ShaderScene.Config):
        image: Iterable[PydanticImage] = DEFAULT_IMAGE
        depth: Iterable[PydanticImage] = None
        background: Iterable[PydanticImage] = None
        depth_bg: Iterable[PydanticImage] = None

        export_mobile: bool = False

        estimator: DepthEstimator = Field(default_factory=DepthAnythingV2)
        animation: DepthAnimation = Field(default_factory=DepthAnimation)
        upscaler: BrokenUpscaler = Field(default_factory=NoUpscaler)

    config: Config = Factory(Config)

    def commands(self):
        self.cli.description = DEPTHFLOW_ABOUT
        with self.cli.panel(self.scene_panel):
            self.cli.command(self.input)
        with self.cli.panel("ğŸ”§ Preloading"):
            self.cli.command(self.load_estimator, hidden=True)
            self.cli.command(self.load_upscaler, hidden=True)
        # with self.cli.panel("Tools"):
        #     self.cli.command(self.export_mobile)
        with self.cli.panel("ğŸŒŠ Depth estimator"):
            self.cli.command(DepthAnythingV2, post=self.set_estimator, name="da2")
        with self.cli.panel("ğŸš€ Animation components"):
            _hidden = Environment.flag("ADVANCED", 0)
            for animation in Animation.members():
                if issubclass(animation, ComponentBase):
                    self.cli.command(animation, post=self.config.animation.add, hidden=_hidden)

    def input(self,
              image: Annotated[list[str], Option("--image", "-i")] = None,
              depth: Annotated[list[str], Option("--depth", "-d")] = None,
              background: Annotated[list[str], Option("--background", "-b")] = None,
              depth_bg: Annotated[list[str], Option("--depth-bg", "-db")] = None,
              export_mobile: Annotated[bool, Option("--export-mobile", help="å¯¼å‡ºç§»åŠ¨ç«¯èµ„äº§")] = False,
              ) -> None:
        self.config.image = image
        self.config.depth = depth
        self.config.background = background
        self.config.depth_bg = depth_bg
        self.config.export_mobile = export_mobile

    def build(self) -> None:
        self.image = ShaderTexture(scene=self, name="image").repeat(False)
        self.depth = ShaderTexture(scene=self, name="depth", anisotropy=1).repeat(False)
        self.image_bg = ShaderTexture(scene=self, name="image_bg").repeat(True)
        self.depth_bg = ShaderTexture(scene=self, name="depth_bg", anisotropy=1).repeat(True)
        self.subject_mask = ShaderTexture(scene=self, name="subject_mask", anisotropy=1).repeat(False)

        self.shader.fragment = DEPTH_SHADER
        self.subsample = 2
        self.runtime = 5.0
        self.ssaa = 1.2

    def setup(self) -> None:
        if (not self.config.animation):
            self.config.animation.add(Animation.Orbital())
        self._load_inputs()
        if self.config.export_mobile:
            self.export_mobile()
            # å¯¼å‡ºå®Œæˆåé€€å‡ºï¼Œé¿å…å¯åŠ¨ GUI çª—å£ï¼ˆå¯é€‰ï¼Œçœ‹ä½ æ˜¯å¦è¿˜éœ€è¦çœ‹çª—å£ï¼‰
            import sys
            self.log_info("Export finished. Exiting.")
            sys.exit(0)

    def update(self) -> None:
        self.config.animation.apply(self)

    def handle(self, message: ShaderMessage) -> None:
        ShaderScene.handle(self, message)
        if isinstance(message, ShaderMessage.Window.FileDrop):
            self.input(image=message.first)
            self._load_inputs()

    def pipeline(self) -> Iterable[ShaderVariable]:
        yield from ShaderScene.pipeline(self)
        yield from self.state.pipeline()

    def set_estimator(self, estimator: DepthEstimator) -> DepthEstimator:
        self.config.estimator = estimator
        return self.config.estimator

    def load_estimator(self) -> None:
        self.config.estimator.load_model()

    def load_upscaler(self) -> None:
        self.config.upscaler.download()

    def depth_anything2(self, **options) -> DepthAnythingV2:
        return self.set_estimator(DepthAnythingV2(**options))

    def realesr(self, **options) -> Realesr:
        return self.set_upscaler(Realesr(**options))

    def set_upscaler(self, upscaler: BrokenUpscaler) -> BrokenUpscaler:
        self.config.upscaler = upscaler
        return upscaler

    def _load_inputs(self, echo: bool = True) -> None:
        img_input = self._get_batch_input(self.config.image)
        dep_input = self._get_batch_input(self.config.depth)
        bg_input = self._get_batch_input(self.config.background)
        bg_dep_input = self._get_batch_input(self.config.depth_bg)

        if (img_input is None): return

        self.log_info(f"Loading FG: {img_input}", echo=echo)
        image_pil = self.config.upscaler.upscale(LoadImage(img_input))
        depth_pil = LoadImage(dep_input)
        if depth_pil is None:
            self.log_info("Estimating FG Depth...", echo=echo)
            depth_pil = self.config.estimator.estimate(image_pil)

            # [æ–°å¢] ä¿å­˜åŸå›¾æ·±åº¦å›¾ (ä½¿ç”¨å½’ä¸€åŒ–å‰çš„æ·±åº¦å›¾è¿›è¡Œä¿å­˜)
            if isinstance(img_input, (str, Path)) and not validators.url(str(img_input)):
                input_path = Path(img_input)
                depth_save_path = input_path.parent / f"{input_path.stem}_depth.png"

                # è½¬æ¢æµ®ç‚¹æ·±åº¦å›¾ä¸º8ä½ç°åº¦å›¾ (ç”¨äºä¸­é—´æ–‡ä»¶ä¿å­˜)
                depth_pil_save = normalize_and_convert_depth(depth_pil)

                depth_pil_save.save(depth_save_path)
                self.log_info(f"Saved FG Depth to: {depth_save_path}", echo=echo)

        # ç»Ÿä¸€è½¬ä¸º Image
        if isinstance(depth_pil, np.ndarray):
            depth_pil = Image.fromarray(depth_pil)

        # === ã€æ–°å¢/ä¿®æ”¹ã€‘å¯¹å‰æ™¯æ·±åº¦å›¾è¿›è¡Œå½’ä¸€åŒ–å’Œæ ¼å¼è½¬æ¢ (ç”¨äºç¼“å­˜å’Œä¸Šä¼ ) ===
        depth_pil = normalize_and_convert_depth(depth_pil)

        # åˆå§‹åŒ–subject_mask_pilå˜é‡
        subject_mask_pil = None

        if bg_input:
            self.log_info(f"Loading BG: {bg_input}", echo=echo)
            bg_pil = self.config.upscaler.upscale(LoadImage(bg_input))
            bg_depth_pil = LoadImage(bg_dep_input)
            if bg_depth_pil is None:
                self.log_info("Estimating BG Depth...", echo=echo)
                bg_depth_pil = self.config.estimator.estimate(bg_pil)
        else:
            self.log_info("No BG provided. Generating via AI Inpainting...", echo=echo)

            if HAS_GENAI:
                # è°ƒç”¨æˆ‘ä»¬æ–°å†™çš„ generator.py
                try:
                    # ç¡®ä¿å°ºå¯¸ä¸€è‡´
                    if depth_pil.size != image_pil.size:
                        # ä½¿ç”¨å½’ä¸€åŒ–åçš„æ·±åº¦å›¾è¿›è¡Œ resizeï¼Œè™½ç„¶ä¸å¤ªç†æƒ³ï¼Œä½†ä¿æŒä¸€è‡´æ€§
                        depth_pil = depth_pil.resize(image_pil.size, Image.BILINEAR)

                    # è°ƒç”¨å¤§æ¨¡å‹ç”ŸæˆèƒŒæ™¯å’Œä¸»ä½“mask
                    bg_pil, subject_mask_pil = generate_background_ai(image_pil)
                    self.log_info("AI Background Generation Complete.", echo=echo)

                except Exception as e:
                    self.log_error(f"AI Generation Failed: {e}")
                    import traceback
                    traceback.print_exc()
                    bg_pil = Image.new("RGB", image_pil.size, (0, 0, 0))
                    subject_mask_pil = Image.new("L", image_pil.size, 0)
            else:
                self.log_error("Generator module not found. Did you install diffusers?")
                bg_pil = Image.new("RGB", image_pil.size, (0, 0, 0))
                subject_mask_pil = Image.new("L", image_pil.size, 0)

            # ä¿å­˜ç”Ÿæˆçš„èƒŒæ™¯å’Œä¸»ä½“mask
            if isinstance(img_input, (str, Path)) and not validators.url(str(img_input)):
                input_path = Path(img_input)
                bg_save_path = input_path.parent / f"{input_path.stem}_ai_bg.png"
                bg_pil.save(bg_save_path)
                self.log_info(f"Saved AI BG to: {bg_save_path}", echo=echo)

                # ä¿å­˜ä¸»ä½“mask
                mask_save_path = input_path.parent / f"{input_path.stem}_subject_mask.png"
                subject_mask_pil.save(mask_save_path)
                self.log_info(f"Saved Subject Mask to: {mask_save_path}", echo=echo)

            # ä¼°ç®—ç”ŸæˆèƒŒæ™¯çš„æ·±åº¦
            self.log_info("Estimating AI BG Depth...", echo=echo)
            bg_depth_pil = self.config.estimator.estimate(bg_pil)

            if isinstance(bg_depth_pil, np.ndarray):
                bg_depth_pil = Image.fromarray(bg_depth_pil)

            # [ä¿®å¤] ä¿å­˜å‰è½¬ä¸º 'L' æ¨¡å¼ (8-bit Grayscale)ï¼Œä¿®å¤ OSError
            if isinstance(img_input, (str, Path)) and not validators.url(str(img_input)):
                input_path = Path(img_input)
                bg_depth_save_path = input_path.parent / f"{input_path.stem}_ai_bg_depth.png"

                # è½¬æ¢ Mode 'F' -> 'L' (ç”¨äºä¸­é—´æ–‡ä»¶ä¿å­˜)
                bg_depth_pil_save = normalize_and_convert_depth(bg_depth_pil)

                bg_depth_pil_save.save(bg_depth_save_path)
                self.log_info(f"Saved AI BG Depth to: {bg_depth_save_path}", echo=echo)

        if isinstance(bg_depth_pil, np.ndarray):
            bg_depth_pil = Image.fromarray(bg_depth_pil)

        # === ã€æ–°å¢/ä¿®æ”¹ã€‘å¯¹èƒŒæ™¯æ·±åº¦å›¾è¿›è¡Œå½’ä¸€åŒ–å’Œæ ¼å¼è½¬æ¢ (ç”¨äºç¼“å­˜å’Œä¸Šä¼ ) ===
        bg_depth_pil = normalize_and_convert_depth(bg_depth_pil)

        self.resolution = (image_pil.width, image_pil.height)
        self.aspect_ratio = (image_pil.width / image_pil.height)

        # === ã€å…³é”®ä¿®å¤ã€‘ç¼“å­˜ PIL å¯¹è±¡åˆ° self å®ä¾‹ä¸­ ===
        self.pil_image_cache = image_pil
        self.pil_depth_cache = depth_pil  # <--- ç¼“å­˜ 8-bit image
        self.pil_bg_cache = bg_pil
        self.pil_bg_depth_cache = bg_depth_pil  # <--- ç¼“å­˜ 8-bit image

        # ç¡®ä¿ subject_mask_pil æœ€ç»ˆæ˜¯ PIL.Image å¯¹è±¡ (å³ä½¿æ˜¯ç©º mask)
        if subject_mask_pil is None:
            subject_mask_pil = Image.new("L", image_pil.size, 0)

        # åŠ è½½ä¸»ä½“mask
        if subject_mask_pil.size != image_pil.size:
            subject_mask_pil = subject_mask_pil.resize(image_pil.size, Image.BILINEAR)
        if subject_mask_pil.mode != 'L':
            subject_mask_pil = subject_mask_pil.convert('L')

        self.pil_mask_cache = subject_mask_pil
        # === ç¼“å­˜ç»“æŸ ===

        # ä¸Šä¼ åˆ° GPU
        self.image.from_image(self.pil_image_cache)
        self.depth.from_image(self.pil_depth_cache)
        self.image_bg.from_image(self.pil_bg_cache)
        self.depth_bg.from_image(self.pil_bg_depth_cache)
        self.subject_mask.from_image(self.pil_mask_cache)

    def _iter_batch_input(self, item: Optional[LoadableImage]) -> Iterable[LoadableImage]:
        if (item is None): return None
        if isinstance(item, (list, tuple, set)):
            for part in item: yield from self._iter_batch_input(part)
        elif isinstance(item, (bytes, ImageType, np.ndarray)):
            yield item
        elif validators.url(item):
            yield item
        elif (path := BrokenPath.get(item, exists=True)):
            if (path.is_dir()):
                files = (path.glob("*" + x) for x in FileExtensions.Image)
                yield from sorted(flatten(files))
            else:
                yield path
        elif ("*" in str(item)):
            yield from sorted(path.parent.glob(path.name))
        else:
            yield item

    def _get_batch_input(self, item: LoadableImage) -> Optional[LoadableImage]:
        return list_get(list(self._iter_batch_input(item)), self.index)

    def ui(self) -> None:
        if (state := imgui.slider_float("Height", self.state.height, 0, 1, "%.2f"))[0]:
            self.state.height = state[1]
        if (state := imgui.slider_float("Zoom", self.state.zoom, 0.5, 2, "%.2f"))[0]:
            self.state.zoom = state[1]
        if (state := imgui.slider_float("Offset X", self.state.offset_x, -2, 2, "%.2f"))[0]:
            self.state.offset_x = state[1]
        if (state := imgui.slider_float("Offset Y", self.state.offset_y, -2, 2, "%.2f"))[0]:
            self.state.offset_y = state[1]